{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acae1e7d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-19T04:21:56.179665Z",
     "iopub.status.busy": "2024-10-19T04:21:56.178522Z",
     "iopub.status.idle": "2024-10-19T04:21:58.328800Z",
     "shell.execute_reply": "2024-10-19T04:21:58.327763Z"
    },
    "papermill": {
     "duration": 2.157158,
     "end_time": "2024-10-19T04:21:58.331284",
     "exception": false,
     "start_time": "2024-10-19T04:21:56.174126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/cs-506-predicting-customer-churn-using-knn/sample_submission.csv\n",
      "/kaggle/input/cs-506-predicting-customer-churn-using-knn/train.csv\n",
      "/kaggle/input/cs-506-predicting-customer-churn-using-knn/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3cdb71b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T04:21:58.338750Z",
     "iopub.status.busy": "2024-10-19T04:21:58.337551Z",
     "iopub.status.idle": "2024-10-19T04:21:58.512641Z",
     "shell.execute_reply": "2024-10-19T04:21:58.511403Z"
    },
    "papermill": {
     "duration": 0.180918,
     "end_time": "2024-10-19T04:21:58.514897",
     "exception": false,
     "start_time": "2024-10-19T04:21:58.333979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
      "0 -1.731878     0.170812 -0.578192  1.066915  0.990459      -1.102312   \n",
      "1 -1.731647     0.060597 -1.069157  0.709002 -0.727682       0.773857   \n",
      "2 -1.731416     0.708111 -0.700933 -1.438477 -0.727682       0.773857   \n",
      "3 -1.731185     0.377466  1.753888  1.424828  0.650193      -1.102312   \n",
      "4 -1.730954     0.225920  0.526477  0.351089  1.440448      -1.102312   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany  \\\n",
      "0   0.529829        1.022213         1.296669           2.085476   \n",
      "1  -1.887275       -0.978204         0.976132          -0.479475   \n",
      "2   0.529829       -0.978204        -1.598851          -0.479475   \n",
      "3  -1.887275       -0.978204         0.174050          -0.479475   \n",
      "4   0.529829        1.022213        -1.018246          -0.479475   \n",
      "\n",
      "   Geography_Spain  Gender_Male  \n",
      "0        -0.520118     0.870535  \n",
      "1        -0.520118     0.870535  \n",
      "2        -0.520118     0.870535  \n",
      "3        -0.520118     0.870535  \n",
      "4        -0.520118     0.870535  \n",
      "         id  CreditScore       Age    Tenure   Balance  NumOfProducts  \\\n",
      "0  1.732109     1.341848  0.403736 -1.080564 -0.727682       0.773857   \n",
      "1  1.732339     2.636875 -0.455451 -0.364737 -0.727682       0.773857   \n",
      "2  1.732570    -0.738462 -1.437380  1.424828  1.308001      -1.102312   \n",
      "3  1.732801    -0.738462 -0.455451  1.424828 -0.727682       2.650026   \n",
      "4  1.733032     0.473904 -0.209969 -0.722651  1.470414      -1.102312   \n",
      "\n",
      "   HasCrCard  IsActiveMember  EstimatedSalary  Geography_Germany  \\\n",
      "0   0.529829        1.022213         1.231633          -0.479475   \n",
      "1   0.529829        1.022213        -0.248393          -0.479475   \n",
      "2   0.529829        1.022213        -1.205390          -0.479475   \n",
      "3   0.529829       -0.978204        -1.143375          -0.479475   \n",
      "4   0.529829        1.022213        -0.440726          -0.479475   \n",
      "\n",
      "   Geography_Spain  Gender_Male  \n",
      "0        -0.520118    -1.148643  \n",
      "1        -0.520118     0.870535  \n",
      "2        -0.520118    -1.148643  \n",
      "3        -0.520118    -1.148643  \n",
      "4        -0.520118     0.870535  \n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing section\n",
    "\n",
    "# Read Data\n",
    "train_df = pd.read_csv('/kaggle/input/cs-506-predicting-customer-churn-using-knn/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/cs-506-predicting-customer-churn-using-knn/test.csv')\n",
    "\n",
    "# Separate features and target in the training set\n",
    "X_train = train_df.drop(['CustomerId', 'Surname', 'Exited'], axis=1)\n",
    "y_train = train_df['Exited']\n",
    "\n",
    "# Preprocess the training data\n",
    "# Fill missing values with median\n",
    "# X_train.fillna(X_train.median(), inplace=True)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "X_train = pd.get_dummies(X_train, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# Apply the same preprocessing steps to the test data\n",
    "test_ids = test_df['id']\n",
    "X_test = test_df.drop(['CustomerId', 'Surname'], axis=1)\n",
    "# X_test.fillna(X_test.median(), inplace=True)\n",
    "X_test = pd.get_dummies(X_test, columns=['Geography', 'Gender'], drop_first=True)\n",
    "\n",
    "# Ensure both train and test have the same columns after one-hot encoding\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Now, let's scale the features using NumPy and Pandas instead of StandardScaler\n",
    "# Calculate the mean and standard deviation for scaling using training data\n",
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()\n",
    "\n",
    "# Scale the training and test datasets manually\n",
    "X_train_scaled = (X_train - train_mean) / train_std\n",
    "X_test_scaled = (X_test - train_mean) / train_std\n",
    "\n",
    "# Optionally, convert to DataFrame for better handling if needed\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_train.columns)\n",
    "\n",
    "# Convert to NumPy arrays for further processing\n",
    "X_train_np = X_train_scaled_df.to_numpy()\n",
    "y_train_np = y_train.to_numpy()\n",
    "X_test_np = X_test_scaled_df.to_numpy()\n",
    "\n",
    "# Display a preview of the scaled datasets\n",
    "print(X_train_scaled_df.head())\n",
    "print(X_test_scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e56c5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T04:21:58.522112Z",
     "iopub.status.busy": "2024-10-19T04:21:58.521037Z",
     "iopub.status.idle": "2024-10-19T04:41:33.973216Z",
     "shell.execute_reply": "2024-10-19T04:41:33.972112Z"
    },
    "papermill": {
     "duration": 1175.460211,
     "end_time": "2024-10-19T04:41:33.977539",
     "exception": false,
     "start_time": "2024-10-19T04:21:58.517328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction results saved to 'knn_churn_predictions_custom3.csv'\n"
     ]
    }
   ],
   "source": [
    "# Model Building section\n",
    "\n",
    " # Custom function to calculate Euclidean distance\n",
    "def euclidean_distance(row1, row2):\n",
    "    return np.sqrt(np.sum((row1 - row2) ** 2))\n",
    "\n",
    "# Custom function to get the K nearest neighbors\n",
    "def get_k_neighbors(X_train, y_train, test_instance, k):\n",
    "    distances = []\n",
    "    # Calculate the distance between the test_instance and all training data\n",
    "    for i in range(len(X_train)):\n",
    "        dist = euclidean_distance(X_train[i], test_instance)\n",
    "        distances.append((dist, y_train[i]))  # Store distance and the corresponding label\n",
    "    # Sort the distances by distance\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    # Select the top k neighbors\n",
    "    neighbors = distances[:k]\n",
    "    return [neighbor[1] for neighbor in neighbors]\n",
    "\n",
    "# Custom function to predict churn probability using KNN\n",
    "def predict_knn_prob(X_train, y_train, X_test, k):\n",
    "    probabilities = []\n",
    "    # For each test instance, find the k nearest neighbors\n",
    "    for test_instance in X_test:\n",
    "        neighbors = get_k_neighbors(X_train, y_train, test_instance, k)\n",
    "        # Estimate probability as the proportion of class 1 (churn) among neighbors\n",
    "        churn_prob = sum(neighbors) / len(neighbors)\n",
    "        probabilities.append(churn_prob)\n",
    "    return np.array(probabilities)\n",
    "\n",
    "\n",
    "# Predict the churn probabilities for the test set\n",
    "k = 45  # You can adjust the number of neighbors based on tuning\n",
    "y_test_pred_prob = predict_knn_prob(X_train_np, y_train_np, X_test_np, k)\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission_df_custom = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'Exited': y_test_pred_prob\n",
    "})\n",
    "\n",
    "# Save the submission file in the correct format\n",
    "submission_df_custom.to_csv('knn_churn_predictions_custom3.csv', index=False)\n",
    "print(\"Prediction results saved to 'knn_churn_predictions_custom3.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10bffa0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-19T04:41:33.985115Z",
     "iopub.status.busy": "2024-10-19T04:41:33.984068Z",
     "iopub.status.idle": "2024-10-19T08:31:34.472890Z",
     "shell.execute_reply": "2024-10-19T08:31:34.471749Z"
    },
    "papermill": {
     "duration": 13800.500124,
     "end_time": "2024-10-19T08:31:34.480423",
     "exception": false,
     "start_time": "2024-10-19T04:41:33.980299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation ROC AUC: 0.7263 with n_neighbors=1.\n",
      "Validation ROC AUC: 0.7942 with n_neighbors=2.\n",
      "Validation ROC AUC: 0.8244 with n_neighbors=3.\n",
      "Validation ROC AUC: 0.8396 with n_neighbors=4.\n",
      "Validation ROC AUC: 0.8555 with n_neighbors=5.\n",
      "Validation ROC AUC: 0.8629 with n_neighbors=6.\n",
      "Validation ROC AUC: 0.8645 with n_neighbors=7.\n",
      "Validation ROC AUC: 0.8653 with n_neighbors=8.\n",
      "Validation ROC AUC: 0.8703 with n_neighbors=9.\n",
      "Validation ROC AUC: 0.8751 with n_neighbors=10.\n",
      "Validation ROC AUC: 0.8767 with n_neighbors=11.\n",
      "Validation ROC AUC: 0.8762 with n_neighbors=12.\n",
      "Validation ROC AUC: 0.8787 with n_neighbors=13.\n",
      "Validation ROC AUC: 0.8814 with n_neighbors=14.\n",
      "Validation ROC AUC: 0.8844 with n_neighbors=15.\n",
      "Validation ROC AUC: 0.8855 with n_neighbors=16.\n",
      "Validation ROC AUC: 0.8874 with n_neighbors=17.\n",
      "Validation ROC AUC: 0.8885 with n_neighbors=18.\n",
      "Validation ROC AUC: 0.8900 with n_neighbors=19.\n",
      "Validation ROC AUC: 0.8909 with n_neighbors=20.\n",
      "Validation ROC AUC: 0.8923 with n_neighbors=21.\n",
      "Validation ROC AUC: 0.8923 with n_neighbors=22.\n",
      "Validation ROC AUC: 0.8915 with n_neighbors=23.\n",
      "Validation ROC AUC: 0.8920 with n_neighbors=24.\n",
      "Validation ROC AUC: 0.8919 with n_neighbors=25.\n",
      "Validation ROC AUC: 0.8956 with n_neighbors=26.\n",
      "Validation ROC AUC: 0.8973 with n_neighbors=27.\n",
      "Validation ROC AUC: 0.8966 with n_neighbors=28.\n",
      "Validation ROC AUC: 0.8967 with n_neighbors=29.\n",
      "Validation ROC AUC: 0.8973 with n_neighbors=30.\n",
      "Validation ROC AUC: 0.8971 with n_neighbors=31.\n",
      "Validation ROC AUC: 0.8971 with n_neighbors=32.\n",
      "Validation ROC AUC: 0.8968 with n_neighbors=33.\n",
      "Validation ROC AUC: 0.8974 with n_neighbors=34.\n",
      "Validation ROC AUC: 0.8970 with n_neighbors=35.\n",
      "Validation ROC AUC: 0.8974 with n_neighbors=36.\n",
      "Validation ROC AUC: 0.8975 with n_neighbors=37.\n",
      "Validation ROC AUC: 0.8973 with n_neighbors=38.\n",
      "Validation ROC AUC: 0.8980 with n_neighbors=39.\n",
      "Validation ROC AUC: 0.8975 with n_neighbors=40.\n",
      "Validation ROC AUC: 0.8979 with n_neighbors=41.\n",
      "Validation ROC AUC: 0.8984 with n_neighbors=42.\n",
      "Validation ROC AUC: 0.8988 with n_neighbors=43.\n",
      "Validation ROC AUC: 0.8984 with n_neighbors=44.\n",
      "Validation ROC AUC: 0.8988 with n_neighbors=45.\n",
      "Validation ROC AUC: 0.8986 with n_neighbors=46.\n",
      "Validation ROC AUC: 0.8987 with n_neighbors=47.\n",
      "Validation ROC AUC: 0.8987 with n_neighbors=48.\n",
      "Validation ROC AUC: 0.8989 with n_neighbors=49.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Split data for validation (optional for evaluating)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_np, y_train_np, test_size=0.2, random_state=42)\n",
    "\n",
    "# Predict probabilities on the validation set\n",
    "n_neighbors_values = range(1, 50)  # Testing for neighbors from 1 to 50\n",
    "for n_neighbors in n_neighbors_values:\n",
    "    y_val_pred_prob = predict_knn_prob(X_train_split, y_train_split, X_val_split, n_neighbors)\n",
    "    roc_auc = roc_auc_score(y_val_split, y_val_pred_prob)\n",
    "    print(f'Validation ROC AUC: {roc_auc:.4f} with n_neighbors={n_neighbors}.' )\n",
    "    \n",
    "# Evaluate using ROC AUC\n",
    "# roc_auc = roc_auc_score(y_val_split, y_val_pred_prob)\n",
    "# print(f'Validation ROC AUC: {roc_auc:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 8691857,
     "sourceId": 80785,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14981.601892,
   "end_time": "2024-10-19T08:31:35.108758",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-19T04:21:53.506866",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
